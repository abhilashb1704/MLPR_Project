import os
import glob
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from sklearn.utils import shuffle
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import segmentation_models as sm
import pydicom

os.environ["SM_FRAMEWORK"] = "tf.keras"
sm.set_framework('tf.keras')
sm.framework()

# ---------- Directory Paths ----------
train_img_dirs = [
    "/kaggle/input/training-tumorous/Training",
    "/kaggle/input/non-tumoroustraining/Non-tumorous(training)"
]
val_img_dirs = [
    "/kaggle/input/validationtumorous/Val-tumorous",
    "/kaggle/input/non-tumorousvalidation/Non-tumorous(val)"
]
train_mask_dirs = [
    "/kaggle/input/segmented-tumourous/masks-tumtum",
    "/kaggle/input/segmented-tumourous/masks-non-tumor/Non-tumorous(training)"
]
val_mask_dirs = [
    "/kaggle/input/segmented-tumourous/masks-tumtum",
    "/kaggle/input/segmented-tumourous/masks-non-tumor/Non-tumorous(val)"
]

# ---------- Utility: Recursively Collect Files ----------
def recursive_collect_files(dirs, exts):
    files = []
    for d in dirs:
        for ext in exts:
            files.extend(glob.glob(os.path.join(d, '**', ext), recursive=True))
    return sorted(files)

# ---------- Utility: Pair Images and Masks by Filename ----------
def pair_images_and_masks(image_paths, mask_paths):
    mask_dict = {os.path.splitext(os.path.basename(m))[0]: m for m in mask_paths}
    paired_images = []
    paired_masks = []
    for img in image_paths:
        key = os.path.splitext(os.path.basename(img))[0]
        if key in mask_dict:
            paired_images.append(img)
            paired_masks.append(mask_dict[key])
        else:
            print(f"Warning: No mask found for {img}")
    return paired_images, paired_masks

# ---------- Collect and Pair Paths ----------
train_image_paths = recursive_collect_files(train_img_dirs, exts=["*.dcm"])
train_mask_paths = recursive_collect_files(train_mask_dirs, exts=["*.png"])
val_image_paths = recursive_collect_files(val_img_dirs, exts=["*.dcm"])
val_mask_paths = recursive_collect_files(val_mask_dirs, exts=["*.png"])

train_image_paths, train_mask_paths = pair_images_and_masks(train_image_paths, train_mask_paths)
val_image_paths, val_mask_paths = pair_images_and_masks(val_image_paths, val_mask_paths)

print(f"Train images: {len(train_image_paths)} | Train masks: {len(train_mask_paths)}")
print(f"Val images: {len(val_image_paths)} | Val masks: {len(val_mask_paths)}")

# ---------- Loss Functions ----------
def dice_loss(y_true, y_pred):
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + 1e-7) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1e-7)

def focal_loss(gamma=2., alpha=0.25):
    def focal(y_true, y_pred):
        y_pred = tf.keras.backend.clip(y_pred, tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon())
        cross_entropy = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)
        weight = alpha * tf.pow(1 - y_pred, gamma) * y_true + (1 - alpha) * tf.pow(y_pred, gamma) * (1 - y_true)
        return tf.reduce_mean(weight * cross_entropy)
    return focal

def combined_loss(y_true, y_pred):
    return dice_loss(y_true, y_pred) + focal_loss()(y_true, y_pred)

# ---------- DICOM Reading and Preprocessing ----------
def read_dicom_image(path):
    ds = pydicom.dcmread(path)
    img = ds.pixel_array.astype(np.float32)
    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):
        img = img * float(ds.RescaleSlope) + float(ds.RescaleIntercept)
    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    # Handle multi-channel images robustly
    if img.ndim == 3:
        if img.shape[2] == 3:
            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        elif img.shape[2] == 4:
            img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)
        else:
            img = img[:, :, 0]
    elif img.ndim > 3:
        img = img.squeeze()
        if img.ndim == 3 and img.shape[2] in [3, 4]:
            img = img[:, :, 0]
    return img

def preprocess_image(image, clip_percentiles=(1, 99)):
    img = np.ascontiguousarray(image)
    if img.ndim > 2:
        img = img.squeeze()
    img = img.astype(np.uint8)
    clahe = cv2.createCLAHE(clipLimit=2.0)
    img = clahe.apply(img)
    p_low, p_high = np.percentile(img, clip_percentiles)
    img = np.clip(img, p_low, p_high)
    img = ((img - p_low) / (p_high - p_low + 1e-7)) * 255
    return img.astype(np.uint8)

# ---------- Data Generator ----------
def data_generator(image_paths, mask_paths, batch_size=8, augment=True, use_rgb=False):
    while True:
        image_paths, mask_paths = shuffle(image_paths, mask_paths)
        for i in range(0, len(image_paths), batch_size):
            batch_imgs = []
            batch_masks = []
            for img_path, mask_path in zip(image_paths[i:i + batch_size], mask_paths[i:i + batch_size]):
                try:
                    img = read_dicom_image(img_path)
                    assert img.ndim == 2, f"Unexpected image shape: {img.shape}"
                    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                    img = preprocess_image(img)
                    img = cv2.resize(img, (256, 256))
                    mask = cv2.resize(mask, (256, 256))
                    if augment and np.random.rand() < 0.5:
                        img = cv2.flip(img, 1)
                        mask = cv2.flip(mask, 1)
                    if augment and np.random.rand() < 0.5:
                        angle = np.random.choice([90, 180, 270])
                        img = np.rot90(img, k=angle // 90)
                        mask = np.rot90(mask, k=angle // 90)
                    if augment and np.random.rand() < 0.3:
                        brightness = np.random.uniform(0.8, 1.2)
                        img = np.clip(img * brightness, 0, 255)
                    if use_rgb:
                        img = np.stack([img] * 3, axis=-1)
                    else:
                        img = img[..., np.newaxis]
                    mask = (mask > 127).astype(np.float32)[..., np.newaxis]
                    batch_imgs.append(img / 255.0)
                    batch_masks.append(mask)
                except Exception as e:
                    print(f"Error processing {img_path}: {e}")
                    continue
            if batch_imgs and batch_masks:
                yield np.array(batch_imgs), np.array(batch_masks)

# ---------- UNet Models ----------
def build_pretrained_unet(input_shape=(256, 256, 3), encoder_weights='imagenet'):
    return sm.Unet('resnet34', input_shape=input_shape, encoder_weights=encoder_weights, classes=1, activation='sigmoid')

def conv_block(x, filters, dropout_rate=0.3):
    x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)
    x = layers.Dropout(dropout_rate)(x)
    x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)
    return x

def build_simple_unet(input_shape=(256, 256, 1)):
    inputs = layers.Input(input_shape)
    c1 = conv_block(inputs, 64)
    p1 = layers.MaxPooling2D()(c1)
    c2 = conv_block(p1, 128)
    p2 = layers.MaxPooling2D()(c2)
    c3 = conv_block(p2, 256)
    p3 = layers.MaxPooling2D()(c3)
    c4 = conv_block(p3, 512)
    p4 = layers.MaxPooling2D()(c4)
    bn = conv_block(p4, 1024)
    u1 = layers.UpSampling2D()(bn)
    u1 = layers.concatenate([u1, c4])
    c5 = conv_block(u1, 512)
    u2 = layers.UpSampling2D()(c5)
    u2 = layers.concatenate([u2, c3])
    c6 = conv_block(u2, 256)
    u3 = layers.UpSampling2D()(c6)
    u3 = layers.concatenate([u3, c2])
    c7 = conv_block(u3, 128)
    u4 = layers.UpSampling2D()(c7)
    u4 = layers.concatenate([u4, c1])
    c8 = conv_block(u4, 64)
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c8)
    return models.Model(inputs, outputs)

# ---------- Training Setup ----------
use_pretrained = True
input_shape = (256, 256, 3) if use_pretrained else (256, 256, 1)

train_gen = data_generator(train_image_paths, train_mask_paths, batch_size=8, use_rgb=use_pretrained)
val_gen = data_generator(val_image_paths, val_mask_paths, batch_size=8, use_rgb=use_pretrained)

if use_pretrained:
    model = build_pretrained_unet(input_shape=input_shape, encoder_weights='imagenet')
else:
    model = build_simple_unet(input_shape=input_shape)

model.compile(optimizer=optimizers.Adam(1e-4), loss=combined_loss, metrics=['accuracy'])

callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5)
]

# ---------- Train ----------
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=50,
    steps_per_epoch=max(1, len(train_image_paths) // 8),
    validation_steps=max(1, len(val_image_paths) // 8),
    callbacks=callbacks
)
